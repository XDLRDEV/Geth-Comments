

# 以太坊源码分析-挖矿算法

ethash包中包含几个algorithm开头的文件，这些文件的内容是pow核心算法，用来支持挖矿操作。

建议先阅读[以太坊源码分析-挖矿流程](./以太坊源码分析-挖矿流程.md)。

## 算法

在共识引擎的`mine()`函数(位于./consensus/ethash/sealer.go)中，下面这句话是挖矿的重点

> ```go
> digest, result := hashimotoFull(dataset.dataset, hash, nonce)
> //dataset.dataset是一个巨大的辅助数据集，hash是区块头哈希，nonce是一个ethash.rand.Int63()生成的非负64位随机数，也称为seed
> ```

每次拿到digest和result，都会进行如下判断

> ```go
> if new(big.Int).SetBytes(result).Cmp(target) <= 0 {
>   // 找到正确result，停止挖矿，返回结果
>   ...
> }
> //用result和target进行比较，而target  = new(big.Int).Div(two256, header.Difficulty)就是用区块头的难度值计算出来的。所以，我们可以通过调整Difficulty值，来控制pow运算难度，生成正确nonce的难度，达到pow工作量可控的目标。
> ```

###### hashimotoFull函数

```go
// 在传入的数据集中通过hash和nonce值计算加密值
func hashimotoFull(dataset []uint32, hash []byte, nonce uint64) ([]byte, []byte) {
    // 定义一个lookup函数，用于在数据集中查找数据，返回dataset中从index开始一个字长(16位)的数据
	lookup := func(index uint32) []uint32 {
		offset := index * hashWords // hashWords是定义的常量值 =16
		return dataset[offset : offset+hashWords]
	}
	// hashimotoFull函数做的工作就是声明了原始数据集的分割函数，然后把数据等交给hashimoto函数。
	return hashimoto(hash, nonce, uint64(len(dataset))*4, lookup)
}
```

###### lookup函数

>  ```go
>  // 定义一个lookup函数，用于在数据集中查找数据，返回dataset中从index开始一个字长(16位)的数据
> 	lookup := func(index uint32) []uint32 {
> 		offset := index * hashWords // hashWords是定义的常量值 =16
> 		return dataset[offset : offset+hashWords]
> 	}
>  ```
>
> lookup其实是从一个及其随机的dataset中取定长的片段作为了index的hash value使用

###### hashimoto函数

```go
// hashimoto aggregates data from the full dataset in order to produce our final
// value for a particular header hash and nonce.
func hashimoto(hash []byte, nonce uint64, size uint64, lookup func(index uint32) []uint32) ([]byte, []byte) {
	// Calculate the number of theoretical rows (we use one buffer nonetheless)
	rows := uint32(size / mixBytes) // mixBytes常数 =128

	// Combine header+nonce into a 64 byte seed
	seed := make([]byte, 40)
	copy(seed, hash)
	binary.LittleEndian.PutUint64(seed[32:], nonce)

	seed = crypto.Keccak512(seed)
	seedHead := binary.LittleEndian.Uint32(seed)

	// Start the mix with replicated seed
	mix := make([]uint32, mixBytes/4)
	for i := 0; i < len(mix); i++ {
		mix[i] = binary.LittleEndian.Uint32(seed[i%16*4:])
	}
	// Mix in random dataset nodes
	temp := make([]uint32, len(mix))

	for i := 0; i < loopAccesses; i++ {
		parent := fnv(uint32(i)^seedHead, mix[i%len(mix)]) % rows
		for j := uint32(0); j < mixBytes/hashBytes; j++ {
			copy(temp[j*hashWords:], lookup(2*parent+j))
		}
		fnvHash(mix, temp)
	}
	// Compress mix
	for i := 0; i < len(mix); i += 4 {
		mix[i/4] = fnv(fnv(fnv(mix[i], mix[i+1]), mix[i+2]), mix[i+3])
	}
	mix = mix[:len(mix)/4]

	digest := make([]byte, common.HashLength)
	for i, val := range mix {
		binary.LittleEndian.PutUint32(digest[i*4:], val)
	}
	return digest, crypto.Keccak256(append(seed, digest...))
}
```

此函数接受了四个参数：

+ `hash []byte` ，区块头哈希
+ `nonce uint64`，传入的随机数seed
+ `size uint64`，`dataset []uint32`的长度的4倍，所以`size`是以字节为单位计算的
+ `lookup func(index uint32) []uint32`，lookup函数，返回dataset中从index开始一个字长(16位)的数据

然后干了这些事情：

+ 以128字节为一行，算出`dataset`的行数，即`size/128`
+ 将32位`hash`和8位`nonce`组合得到`seed`
+ 对`seed`做Keccak512哈希运算得到其64位的哈希值，并将其哈希值再赋给`seed`
+ 取`seed`的前32位作为`seedHead`
+ 声明一个可以存32个uint32数的数组`mix`
+ 将`seed`的值写入`mix`，`mix`容量是`seed`大小的二倍，所以`mix`前后存了两个完全相同的`seed`
+ 通过`dataset`和64次for循环以及异或操作来混淆`mix`
+ 将`mix`折叠(压缩)成一个长度缩小成原长1/4的uint32数组
+ 将折叠后的`mix[]`由长度为8的uint32型数组直接转化成一个长度32的byte数组，作为**返回值`digest`**
+ 同时将之前的`seed[]`数组与`digest`合并再取一次SHA-256哈希值，得到的长度32的byte数组，作为**返回值`result`**

`fnv`算法是一个代码简单的算法：

```go
func fnv(a, b uint32) uint32 {
	return a*0x01000193 ^ b
}
```



