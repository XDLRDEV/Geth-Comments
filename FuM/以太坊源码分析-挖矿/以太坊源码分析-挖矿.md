# 以太坊源码分析-挖矿

+ 在源码目录中，`consensus`提供了以太坊的一些共识算法，`miner`提供以太坊的区块创建和挖矿。
+ **挖矿(`mine`)**是指矿工节点互相竞争生成新区块以写入整个区块链获得奖励的过程。**共识(`consensus`)**是指区块链各个节点对下一个区块的内容形成一致的过程。在以太坊中, `miner`包向外提供挖矿功能，`consensus`包对外提供共识引擎接口。
+ 在控制台输入的`mine.start()`命令入口为`/eth/api`中下面这个函数

```go
/* FuM:参数即挖矿所需协程数量 */
func (api *PrivateMinerAPI) Start(threads *int) error {
	if threads == nil {
		return api.e.StartMining(runtime.NumCPU())
	}
	return api.e.StartMining(*threads)
}
```

`StartMining()`函数设置了挖矿线程数，读取并在交易池中设置`gasPrice`，配置本地矿工地址。如果采用的是`clique`共识引擎（`PoA`），则会对钱包账户等进行初始化。最后启动协程`s.miner.Start(eb)`。

```go
// StartMining starts the miner with the given number of CPU threads. If mining
// is already running, this method adjust the number of threads allowed to use
// and updates the minimum price required by the transaction pool.
func (s *Ethereum) StartMining(threads int) error {
	// Update the thread count within the consensus engine
	type threaded interface {
		SetThreads(threads int)
	}
	if th, ok := s.engine.(threaded); ok {
		log.Info("Updated mining threads", "threads", threads)
		if threads == 0 {
			threads = -1 // Disable the miner from within
		}
		th.SetThreads(threads)
	}
	// If the miner was not running, initialize it
	if !s.IsMining() {
		// Propagate the initial price point to the transaction pool
		s.lock.RLock()//
		price := s.gasPrice
		s.lock.RUnlock()
		s.txPool.SetGasPrice(price)

		// Configure the local mining address
		eb, err := s.Etherbase()
		if err != nil {
			log.Error("Cannot start mining without etherbase", "err", err)
			return fmt.Errorf("etherbase missing: %v", err)
		}
		if clique, ok := s.engine.(*clique.Clique); ok {
			wallet, err := s.accountManager.Find(accounts.Account{Address: eb})
			if wallet == nil || err != nil {
				log.Error("Etherbase account unavailable locally", "err", err)
				return fmt.Errorf("signer missing: %v", err)
			}
			clique.Authorize(eb, wallet.SignData)
		}
		// If mining is started, we can disable the transaction rejection mechanism
		// introduced to speed sync times.
		atomic.StoreUint32(&s.protocolManager.acceptTxs, 1)

		go s.miner.Start(eb)
	}
	return nil
}
```

`Start()`函数设置矿工地址参数后检查环境开始挖矿。

```go
func (miner *Miner) Start(coinbase common.Address) {
	atomic.StoreInt32(&miner.shouldStart, 1)
	miner.SetEtherbase(coinbase)

	if atomic.LoadInt32(&miner.canStart) == 0 {
		log.Info("Network syncing, will start miner afterwards")
		return
	}
	miner.worker.start()
}
```

`miner.worker.start()`函数向管道中传送空结构体作为信号触发挖矿操作。

```go
// start sets the running status as 1 and triggers new work submitting.
func (w *worker) start() {
   atomic.StoreInt32(&w.running, 1)
   w.startCh <- struct{}{}
}
```

### 挖矿

`miner`包主要由`miner.go` `worker.go`两个文件组成。

- `Miner` 负责与外部交互和高层次的挖矿控制。
- `worker` 负责低层次的挖矿控制。

`miner.go`中声明了`miner`对象，同样`worker.go`中声明了`worker`对象，`worker`是`miner`结构体中的一项，属于从属关系。

### 生命周期

+ 在`geth`控制台编译启动时，一个`miner`对象及其从属的`worker`对象就已经被声明。同时启动挖矿相关协程等待挖矿指令。
+ 在接收到挖矿指令后，`worker`开始执行挖矿的一些操作。

### 代码分析

#### `miner`的定义

```go
type Miner struct {
	mux      *event.TypeMux //事件接收器
	worker   *worker //从属的worker
	coinbase common.Address //矿工地址
	eth      Backend 
	engine   consensus.Engine //共识引擎
	exitCh   chan struct{} //退出通道，接收到指令后会停止挖矿

	canStart    int32 // can start indicates whether we can start the mining operation
	shouldStart int32 // should start indicates whether we should start after sync
}
```

#### `worker`的定义

```go
type worker struct {
	config      *Config
	chainConfig *params.ChainConfig
	engine      consensus.Engine
	eth         Backend
	chain       *core.BlockChain

	// Feeds
	pendingLogsFeed event.Feed

	// Subscriptions
	mux          *event.TypeMux
	txsCh        chan core.NewTxsEvent
	txsSub       event.Subscription
	chainHeadCh  chan core.ChainHeadEvent
	chainHeadSub event.Subscription
	chainSideCh  chan core.ChainSideEvent
	chainSideSub event.Subscription

	// Channels
	newWorkCh          chan *newWorkReq
	taskCh             chan *task
	resultCh           chan *types.Block
	startCh            chan struct{}
	exitCh             chan struct{}
	resubmitIntervalCh chan time.Duration
	resubmitAdjustCh   chan *intervalAdjust

	current      *environment                 // An environment for current running cycle.
	localUncles  map[common.Hash]*types.Block // A set of side blocks generated locally as the possible uncle blocks.
	remoteUncles map[common.Hash]*types.Block // A set of side blocks as the possible uncle blocks.
	unconfirmed  *unconfirmedBlocks           // A set of locally mined blocks pending canonicalness confirmations.

	mu       sync.RWMutex // The lock used to protect the coinbase and extra fields
	coinbase common.Address
	extra    []byte

	pendingMu    sync.RWMutex
	pendingTasks map[common.Hash]*task

	snapshotMu    sync.RWMutex // The lock used to protect the block snapshot and state snapshot
	snapshotBlock *types.Block
	snapshotState *state.StateDB

	// atomic status counters
	running int32 // The indicator whether the consensus engine is running or not.
	newTxs  int32 // New arrival transaction count since last sealing work submitting.

	// External functions
	isLocalBlock func(block *types.Block) bool // Function used to determine whether the specified block is mined by local miner.

	// Test hooks
	newTaskHook  func(*task)                        // Method to call upon receiving a new sealing task.
	skipSealHook func(*task) bool                   // Method to decide whether skipping the sealing.
	fullTaskHook func()                             // Method to call before pushing the full sealing task.
	resubmitHook func(time.Duration, time.Duration) // Method to call upon updating resubmitting interval.
}
```

`worker`中主要定义了一些挖矿的配置，声明一些通道来控制挖矿进程，以后再详细分析。

`worker`的构造函数对`worker`进行示例化并启动四个相关协程，这四个协程在控制台启动时就已经启动。

```go
/* FuM:用于根据给定参数构建 worker */
func newWorker(config *Config, chainConfig *params.ChainConfig, engine consensus.Engine, eth Backend, mux *event.TypeMux, isLocalBlock func(*types.Block) bool, init bool) *worker {
	worker := &worker{
		config:       config,
		chainConfig:  chainConfig,
		engine:       engine,
		eth:          eth,
		mux:          mux, /* FuM: 向外部发布已经挖到新Block*/
		chain:        eth.BlockChain(),
		isLocalBlock: isLocalBlock,
		/* FuM:以上几项均来自Miner */
		localUncles:        make(map[common.Hash]*types.Block),
		remoteUncles:       make(map[common.Hash]*types.Block),
		unconfirmed:        newUnconfirmedBlocks(eth.BlockChain(), miningLogAtDepth),
		pendingTasks:       make(map[common.Hash]*task),
		txsCh:              make(chan core.NewTxsEvent, txChanSize), /* FuM: 从后台eth接收新的Block的Channel*/
		chainHeadCh:        make(chan core.ChainHeadEvent, chainHeadChanSize),
		chainSideCh:        make(chan core.ChainSideEvent, chainSideChanSize),
		newWorkCh:          make(chan *newWorkReq),
		taskCh:             make(chan *task),
		resultCh:           make(chan *types.Block, resultQueueSize),
		exitCh:             make(chan struct{}),
		startCh:            make(chan struct{}, 1),
		resubmitIntervalCh: make(chan time.Duration),
		resubmitAdjustCh:   make(chan *intervalAdjust, resubmitAdjustChanSize),
	}
	// Subscribe NewTxsEvent for tx pool
	worker.txsSub = eth.TxPool().SubscribeNewTxsEvent(worker.txsCh)
	// Subscribe events for blockchain
	worker.chainHeadSub = eth.BlockChain().SubscribeChainHeadEvent(worker.chainHeadCh)
	worker.chainSideSub = eth.BlockChain().SubscribeChainSideEvent(worker.chainSideCh)

	// Sanitize recommit interval if the user-specified one is too short.
	recommit := worker.config.Recommit
	if recommit < minRecommitInterval {
		log.Warn("Sanitizing miner recommit interval", "provided", recommit, "updated", minRecommitInterval)
		recommit = minRecommitInterval
	}

	go worker.mainLoop()
	go worker.newWorkLoop(recommit)
	go worker.resultLoop()
	go worker.taskLoop()

	// Submit first work to initialize pending state.
	if init {
		worker.startCh <- struct{}{}
	}
	return worker
}
```

### 挖矿流程

```go
// start sets the running status as 1 and triggers new work submitting.
func (w *worker) start() {
	atomic.StoreInt32(&w.running, 1)
	w.startCh <- struct{}{}
}
```

当开始接收到挖矿指令后会触发此函数：使用原子操作将运行状态设置为`1`，然后向`worker`的`startCh`通道写如一个空结构体。之后，协程`worker.newWorkLoop()`会接收到`startCh`的空结构体，看`worker.newWorkLoop()`代码

```go
// newWorkLoop is a standalone goroutine to submit new mining work upon received events.
func (w *worker) newWorkLoop(recommit time.Duration) {
	var (
		interrupt   *int32
		minRecommit = recommit // minimal resubmit interval specified by user.
		timestamp   int64      // timestamp for each round of mining.
	)

	timer := time.NewTimer(0)
	<-timer.C // discard the initial tick

	// commit aborts in-flight transaction execution with given signal and resubmits a new one.
	commit := func(noempty bool, s int32) {
		if interrupt != nil {
			atomic.StoreInt32(interrupt, s)
		}
		interrupt = new(int32)
		w.newWorkCh <- &newWorkReq{interrupt: interrupt, noempty: noempty, timestamp: timestamp}
		timer.Reset(recommit)
		atomic.StoreInt32(&w.newTxs, 0)
	}
	// recalcRecommit recalculates the resubmitting interval upon feedback.
	recalcRecommit := func(target float64, inc bool) {
		var (
			prev = float64(recommit.Nanoseconds())
			next float64
		)
		if inc {
			next = prev*(1-intervalAdjustRatio) + intervalAdjustRatio*(target+intervalAdjustBias)
			// Recap if interval is larger than the maximum time interval
			if next > float64(maxRecommitInterval.Nanoseconds()) {
				next = float64(maxRecommitInterval.Nanoseconds())
			}
		} else {
			next = prev*(1-intervalAdjustRatio) + intervalAdjustRatio*(target-intervalAdjustBias)
			// Recap if interval is less than the user specified minimum
			if next < float64(minRecommit.Nanoseconds()) {
				next = float64(minRecommit.Nanoseconds())
			}
		}
		recommit = time.Duration(int64(next))
	}
	// clearPending cleans the stale pending tasks.
	clearPending := func(number uint64) {
		w.pendingMu.Lock()
		for h, t := range w.pendingTasks {
			if t.block.NumberU64()+staleThreshold <= number {
				delete(w.pendingTasks, h)
			}
		}
		w.pendingMu.Unlock()
	}

	for {
		select {
		case <-w.startCh:
			clearPending(w.chain.CurrentBlock().NumberU64())
			timestamp = time.Now().Unix()
			commit(false, commitInterruptNewHead)

		case head := <-w.chainHeadCh:
			clearPending(head.Block.NumberU64())
			timestamp = time.Now().Unix()
			commit(false, commitInterruptNewHead)

		case <-timer.C:
			// If mining is running resubmit a new work cycle periodically to pull in
			// higher priced transactions. Disable this overhead for pending blocks.
			if w.isRunning() && (w.chainConfig.Clique == nil || w.chainConfig.Clique.Period > 0) {
				// Short circuit if no new transaction arrives.
				if atomic.LoadInt32(&w.newTxs) == 0 {
					timer.Reset(recommit)
					continue
				}
				commit(true, commitInterruptResubmit)
			}

		case interval := <-w.resubmitIntervalCh:
			// Adjust resubmit interval explicitly by user.
			if interval < minRecommitInterval {
				log.Warn("Sanitizing miner recommit interval", "provided", interval, "updated", minRecommitInterval)
				interval = minRecommitInterval
			}
			log.Info("Miner recommit interval update", "from", minRecommit, "to", interval)
			minRecommit, recommit = interval, interval

			if w.resubmitHook != nil {
				w.resubmitHook(minRecommit, recommit)
			}

		case adjust := <-w.resubmitAdjustCh:
			// Adjust resubmit interval by feedback.
			if adjust.inc {
				before := recommit
				recalcRecommit(float64(recommit.Nanoseconds())/adjust.ratio, true)
				log.Trace("Increase miner recommit interval", "from", before, "to", recommit)
			} else {
				before := recommit
				recalcRecommit(float64(minRecommit.Nanoseconds()), false)
				log.Trace("Decrease miner recommit interval", "from", before, "to", recommit)
			}

			if w.resubmitHook != nil {
				w.resubmitHook(minRecommit, recommit)
			}

		case <-w.exitCh:
			return
		}
	}
}
```

54行之前进行了一些变量和函数的声明，之后进入`for`循环阻塞等待通道指令。在上面分析中`start()`函数已经往`w.startCh`写入数据，此时不在阻塞，执行下面这个`case`

```go
case <-w.startCh:
			clearPending(w.chain.CurrentBlock().NumberU64())//清除陈旧的pending任务
			timestamp = time.Now().Unix()//拿到现在的unix时间戳作为本轮挖矿开始时间
			commit(false, commitInterruptNewHead)
```

`commit`使用给定的信号中止正在进行的事务处理，然后重新提交一个新的信号。

```go
	commit := func(noempty bool, s int32) {
		if interrupt != nil {
			atomic.StoreInt32(interrupt, s)
		}
		interrupt = new(int32)
		w.newWorkCh <- &newWorkReq{interrupt: interrupt, noempty: noempty, timestamp: timestamp}
		timer.Reset(recommit)
		atomic.StoreInt32(&w.newTxs, 0)
	}
```

第六行向`worker`的`newWorkCh`管道写入新任务指令，于是协程`mainLoop()`停止阻塞，`mainLoop()`部分代码如下

```go
func (w *worker) mainLoop() {
	defer w.txsSub.Unsubscribe()
	defer w.chainHeadSub.Unsubscribe()
	defer w.chainSideSub.Unsubscribe()

	for {
		select {
		/* FuM:区块链中已经加入了一个新的区块作为整个链的链头，这时worker的回应是立即开始准备挖掘下一个新区块 */
		case req := <-w.newWorkCh:
			w.commitNewWork(req.interrupt, req.noempty, req.timestamp) /* FuM: 挖矿工作 */
		/* FuM:区块链中加入了一个新区块作为当前链头的旁支，worker会把这个区块收纳进localUncles[]或remoteUncles[]，作为下一个挖掘新区块可能的Uncle之一 */
		case ev := <-w.chainSideCh:
		···
```

第9行`case`接收到新任务指令，开始执行`w.commitNewWork(req.interrupt, req.noempty, req.timestamp)`挖矿工作。

```go
func (w *worker) commitNewWork(interrupt *int32, noempty bool, timestamp int64) {
	w.mu.RLock()
	defer w.mu.RUnlock()

	tstart := time.Now()
	parent := w.chain.CurrentBlock()

	if parent.Time() >= uint64(timestamp) {
		timestamp = int64(parent.Time() + 1)
	}
	// this will ensure we're not going off too far in the future
	if now := time.Now().Unix(); timestamp > now+1 {
		wait := time.Duration(timestamp-now) * time.Second
		log.Info("Mining too far in the future", "wait", common.PrettyDuration(wait))
		time.Sleep(wait)
	}

	num := parent.Number()
	/* FuM:创建区块头 */
	header := &types.Header{
		ParentHash: parent.Hash(),
		Number:     num.Add(num, common.Big1),
		GasLimit:   core.CalcGasLimit(parent, w.config.GasFloor, w.config.GasCeil),
		Extra:      w.extra,
		Time:       uint64(timestamp),
	}
	// Only set the coinbase if our consensus engine is running (avoid spurious block rewards)
	if w.isRunning() {
		if w.coinbase == (common.Address{}) {
			log.Error("Refusing to mine without etherbase")
			return
		}
		header.Coinbase = w.coinbase
	}
	if err := w.engine.Prepare(w.chain, header); err != nil {
		log.Error("Failed to prepare header for mining", "err", err)
		return
	}
	// If we are care about TheDAO hard-fork check whether to override the extra-data or not
	/* FuM: 是否支持DAO事件硬分叉*/
	if daoBlock := w.chainConfig.DAOForkBlock; daoBlock != nil {
		// Check whether the block is among the fork extra-override range
		limit := new(big.Int).Add(daoBlock, params.DAOForkExtraRange)
		if header.Number.Cmp(daoBlock) >= 0 && header.Number.Cmp(limit) < 0 {
			// Depending whether we support or oppose the fork, override differently
			if w.chainConfig.DAOForkSupport {
				header.Extra = common.CopyBytes(params.DAOForkBlockExtra)
			} else if bytes.Equal(header.Extra, params.DAOForkBlockExtra) {
				header.Extra = []byte{} // If miner opposes, don't let it use the reserved extra-data
			}
		}
	}
	// Could potentially happen if starting to mine in an odd state.
	err := w.makeCurrent(parent, header)
	if err != nil {
		log.Error("Failed to create mining context", "err", err)
		return
	}
	// Create the current work task and check any fork transitions needed
	env := w.current
	if w.chainConfig.DAOForkSupport && w.chainConfig.DAOForkBlock != nil && w.chainConfig.DAOForkBlock.Cmp(header.Number) == 0 {
		misc.ApplyDAOHardFork(env.state)
	}
	// Accumulate the uncles for the current block
	uncles := make([]*types.Header, 0, 2)
	commitUncles := func(blocks map[common.Hash]*types.Block) {
		// Clean up stale uncle blocks first
		/* FuM: 删除旧块*/
		for hash, uncle := range blocks {
			if uncle.NumberU64()+staleThreshold <= header.Number.Uint64() {
				delete(blocks, hash)
			}
		}
		for hash, uncle := range blocks {
			if len(uncles) == 2 {
				break
			}
			/* FuM: 校验一些参数，提交叔块*/
			if err := w.commitUncle(env, uncle.Header()); err != nil {
				log.Trace("Possible uncle rejected", "hash", hash, "reason", err)
			} else {
				log.Debug("Committing new uncle to block", "hash", hash)
				uncles = append(uncles, uncle.Header())
			}
		}
	}
	// Prefer to locally generated uncle
	commitUncles(w.localUncles)
	commitUncles(w.remoteUncles)

	if !noempty {
		// Create an empty block based on temporary copied state for sealing in advance without waiting block
		// execution finished.
		/* FuM:根据临时复制状态创建一个空块，以便提前封装，而无需等待块执行完成。 */
		w.commit(uncles, nil, false, tstart)
	}
	//从交易池中取交易
	// Fill the block with all available pending transactions.
	pending, err := w.eth.TxPool().Pending()
	if err != nil {
		log.Error("Failed to fetch pending transactions", "err", err)
		return
	}
	// Short circuit if there is no available pending transactions
	if len(pending) == 0 {
		w.updateSnapshot()
		return
	}
	// Split the pending transactions into locals and remotes
	localTxs, remoteTxs := make(map[common.Address]types.Transactions), pending
	for _, account := range w.eth.TxPool().Locals() {
		if txs := remoteTxs[account]; len(txs) > 0 {
			delete(remoteTxs, account)
			localTxs[account] = txs
		}
	}
  //对取出的交易集整理并执行
	if len(localTxs) > 0 {
		txs := types.NewTransactionsByPriceAndNonce(w.current.signer, localTxs)
		if w.commitTransactions(txs, w.coinbase, interrupt) {
			return
		}
	}
	if len(remoteTxs) > 0 {
		txs := types.NewTransactionsByPriceAndNonce(w.current.signer, remoteTxs)
		if w.commitTransactions(txs, w.coinbase, interrupt) {
			return
		}
	}
	w.commit(uncles, w.fullTaskHook, true, tstart)//开始出块
}
```

此函数主要对准备新出的块创建块编号，处理区块头、时间戳，DAO事件硬分叉以及叔块，另外，取出本地和远程交易并执行。处理完毕后，第95行`w.commit(uncles, nil, false, tstart)`开始出块。下面先介绍一下交易执行过程第120和126行`w.commitTransactions(txs, w.coinbase, interrupt)`。`commitTransactions()`函数如下

```go
/* FuM:执行交易*/
func (w *worker) commitTransactions(txs *types.TransactionsByPriceAndNonce, coinbase common.Address, interrupt *int32) bool {
	// Short circuit if current is nil
	if w.current == nil {
		return true
	}

	if w.current.gasPool == nil {
		w.current.gasPool = new(core.GasPool).AddGas(w.current.header.GasLimit)
	}

	var coalescedLogs []*types.Log

	for {
		// In the following three cases, we will interrupt the execution of the transaction.
		// (1) new head block event arrival, the interrupt signal is 1
		// (2) worker start or restart, the interrupt signal is 1
		// (3) worker recreate the mining block with any newly arrived transactions, the interrupt signal is 2.
		// For the first two cases, the semi-finished work will be discarded.
		// For the third case, the semi-finished work will be submitted to the consensus engine.
		if interrupt != nil && atomic.LoadInt32(interrupt) != commitInterruptNone {
			// Notify resubmit loop to increase resubmitting interval due to too frequent commits.
			if atomic.LoadInt32(interrupt) == commitInterruptResubmit {
				ratio := float64(w.current.header.GasLimit-w.current.gasPool.Gas()) / float64(w.current.header.GasLimit)
				if ratio < 0.1 {
					ratio = 0.1
				}
				w.resubmitAdjustCh <- &intervalAdjust{
					ratio: ratio,
					inc:   true,
				}
			}
			return atomic.LoadInt32(interrupt) == commitInterruptNewHead
		}
		// If we don't have enough gas for any further transactions then we're done
		if w.current.gasPool.Gas() < params.TxGas {
			log.Trace("Not enough gas for further transactions", "have", w.current.gasPool, "want", params.TxGas)
			break
		}
		// Retrieve the next transaction and abort if all done
		tx := txs.Peek()
		if tx == nil {
			break
		}
		// Error may be ignored here. The error has already been checked
		// during transaction acceptance is the transaction pool.
		//
		// We use the eip155 signer regardless of the current hf.
		from, _ := types.Sender(w.current.signer, tx)
		// Check whether the tx is replay protected. If we're not in the EIP155 hf
		// phase, start ignoring the sender until we do.
		if tx.Protected() && !w.chainConfig.IsEIP155(w.current.header.Number) {
			log.Trace("Ignoring reply protected transaction", "hash", tx.Hash(), "eip155", w.chainConfig.EIP155Block)

			txs.Pop()
			continue
		}
		// Start executing the transaction
		w.current.state.Prepare(tx.Hash(), common.Hash{}, w.current.tcount)

		logs, err := w.commitTransaction(tx, coinbase)
		switch err {
		case core.ErrGasLimitReached:
			// Pop the current out-of-gas transaction without shifting in the next from the account
			log.Trace("Gas limit exceeded for current block", "sender", from)
			txs.Pop()

		case core.ErrNonceTooLow:
			// New head notification data race between the transaction pool and miner, shift
			log.Trace("Skipping transaction with low nonce", "sender", from, "nonce", tx.Nonce())
			txs.Shift()

		case core.ErrNonceTooHigh:
			// Reorg notification data race between the transaction pool and miner, skip account =
			log.Trace("Skipping account with hight nonce", "sender", from, "nonce", tx.Nonce())
			txs.Pop()

		case nil:
			// Everything ok, collect the logs and shift in the next transaction from the same account
			coalescedLogs = append(coalescedLogs, logs...)
			w.current.tcount++
			txs.Shift()

		default:
			// Strange error, discard the transaction and get the next in line (note, the
			// nonce-too-high clause will prevent us from executing in vain).
			log.Debug("Transaction failed, account skipped", "hash", tx.Hash(), "err", err)
			txs.Shift()
		}
	}

	if !w.isRunning() && len(coalescedLogs) > 0 {
		// We don't push the pendingLogsEvent while we are mining. The reason is that
		// when we are mining, the worker will regenerate a mining block every 3 seconds.
		// In order to avoid pushing the repeated pendingLog, we disable the pending log pushing.

		// make a copy, the state caches the logs and these logs get "upgraded" from pending to mined
		// logs by filling in the block hash when the block was mined by the local miner. This can
		// cause a race condition if a log was "upgraded" before the PendingLogsEvent is processed.
		cpy := make([]*types.Log, len(coalescedLogs))
		for i, l := range coalescedLogs {
			cpy[i] = new(types.Log)
			*cpy[i] = *l
		}
		w.pendingLogsFeed.Send(cpy)
	}
	// Notify resubmit loop to decrease resubmitting interval if current interval is larger
	// than the user-specified one.
	if interrupt != nil {
		w.resubmitAdjustCh <- &intervalAdjust{inc: false}
	}
	return false
}
```

此函数对交易执行环境进行了一些检查，然后进入for循环对交易依次执行，第61行`logs, err := w.commitTransaction(tx, coinbase)`执行了一个交易，下面我们看`commitTransaction()`函数。

```go
//此函数执行单个交易
func (w *worker) commitTransaction(tx *types.Transaction, coinbase common.Address) ([]*types.Log, error) {
   snap := w.current.state.Snapshot()

   receipt, err := core.ApplyTransaction(w.chainConfig, w.chain, &coinbase, w.current.gasPool, w.current.state, w.current.header, tx, &w.current.header.GasUsed, *w.chain.GetVMConfig())
   if err != nil {
      w.current.state.RevertToSnapshot(snap)
      return nil, err
   }
   w.current.txs = append(w.current.txs, tx)
   w.current.receipts = append(w.current.receipts, receipt)

   return receipt.Logs, nil
}
```

此函数先创建状态树快照。然后运行`  receipt, err := core.ApplyTransaction(w.chainConfig, w.chain, &coinbase, w.current.gasPool, w.current.state, w.current.header, tx, &w.current.header.GasUsed, *w.chain.GetVMConfig())`。`ApplyTransaction()`函数进行具体的交易执行（包括转账和智能合约的相关动作），交付gas，这里的gas包括支付给矿工的gas和refundGas。`ApplyTransaction()`函数返回拿到收据`receipt`，如果执行出错就将状态树回滚至刚才创建的快照。执行成功之后记录此已执行交易及其收据，并返回`receipt.Logs`。交易执行完后，执行`w.commit(uncles, nil, false, tstart)`开始出块，代码如下。

```go
// commit runs any post-transaction state modifications, assembles the final block
// and commits new work if consensus engine is running.
func (w *worker) commit(uncles []*types.Header, interval func(), update bool, start time.Time) error {
	// Deep copy receipts here to avoid interaction between different tasks.
	receipts := make([]*types.Receipt, len(w.current.receipts))
	for i, l := range w.current.receipts {
		receipts[i] = new(types.Receipt)
		*receipts[i] = *l
	}
	s := w.current.state.Copy()
	block, err := w.engine.FinalizeAndAssemble(w.chain, w.current.header, s, w.current.txs, uncles, w.current.receipts)
	if err != nil {
		return err
	}
	if w.isRunning() {
		if interval != nil {
			interval()
		}
		select {
		case w.taskCh <- &task{receipts: receipts, state: s, block: block, createdAt: time.Now()}:
			w.unconfirmed.Shift(block.NumberU64() - 1)

			feesWei := new(big.Int)
			for i, tx := range block.Transactions() {
				feesWei.Add(feesWei, new(big.Int).Mul(new(big.Int).SetUint64(receipts[i].GasUsed), tx.GasPrice()))
			}
			feesEth := new(big.Float).Quo(new(big.Float).SetInt(feesWei), new(big.Float).SetInt(big.NewInt(params.Ether)))

			log.Info("Commit new mining work", "number", block.Number(), "sealhash", w.engine.SealHash(block.Header()),
				"uncles", len(uncles), "txs", w.current.tcount, "gas", block.GasUsed(), "fees", feesEth, "elapsed", common.PrettyDuration(time.Since(start)))

		case <-w.exitCh:
			log.Info("Worker has exited")
		}
	}
	if update {
		w.updateSnapshot()
	}
	return nil
}
```

此函数首先深拷贝收据，以避免不同任务之间的交互。构建状态树 `w.current.state` 的副本`s`。**调用共识引擎的方法 `FinalizeAndAssemble() `，根据当前链的状态配置新块的一些参数，累积区块和叔块的奖励，设置最终状态并组装区块得到block。**之后运行可能存在的中断函数(第17行)。

第20行的`case`一定执行，而根据`Go`语言的`select`规则（所有`channel`表达式都会被求值、所有被发送的表达式都会被求值。求值顺序：自上而下、从左到右），下面的`case <-w.exitCh`会在上一个`case`执行完之后尝试接收数据。下面主要看挖矿的`case`，也就是第20行的`case`执行情况，如下代码：

```go
case w.taskCh <- &task{receipts: receipts, state: s, block: block, createdAt: time.Now()}:
			w.unconfirmed.Shift(block.NumberU64() - 1)//删除待确认区块列表中的过期区块

			feesWei := new(big.Int)
			for i, tx := range block.Transactions() {
        //累计区块 block 中所有交易消耗 Gas 的总和 feesWei。没有交易就不累计。
				feesWei.Add(feesWei, new(big.Int).Mul(new(big.Int).SetUint64(receipts[i].GasUsed), tx.GasPrice()))
			}
			feesEth := new(big.Float).Quo(new(big.Float).SetInt(feesWei), new(big.Float).SetInt(big.NewInt(params.Ether)))//将 feesWei 转换成 feesEth，即消耗的总以太币

			log.Info("Commit new mining work", "number", block.Number(), "sealhash", w.engine.SealHash(block.Header()),
				"uncles", len(uncles), "txs", w.current.tcount, "gas", block.GasUsed(), "fees", feesEth, "elapsed", common.PrettyDuration(time.Since(start)))
```

上述代码依次执行了以下几项工作：

+ 构建任务 `task`，并将其发送到通道 `taskCh`，从而驱动协程 `worker.taskLoop()`的工作流程，只有当这个case执行完之后，协程 `worker.taskLoop()`中的`case task := <-w.taskCh`才会被求值并工作
+ 删除待确认区块列表中的过期区块
+ 计算区块中交易花费的`Gas`
+ 将` feesWei` 转换成 `feesEth`，即消耗的总以太币
+ 至此，已经打包好了最终的待签名区块，输出一条重要的日志信息。

主要看下第11,12行`log.Info`语句

+ `block.Number()`是当前区块数
+ `w.engine.SealHash(block.Header())`对区块头内容进行rlp编码序列化并返回其哈希
+ `len(uncles)`，`w.current.tcount`，`block.GasUsed()`，`feesEth`，`common.PrettyDuration(time.Since(start)))`分别是叔块长度，交易数量，`gas`花费量，以太币消耗量，执行时间。

此时`w.commit(uncles, nil, false, tstart)`执行完毕。拿到最终的待签名区块后，协程`worker.taskLoop()`中的`case task := <-w.taskCh`开始工作。

```go
case task := <-w.taskCh:
			//Hook函数好像是代码测试用的，待探究
			if w.newTaskHook != nil {
				w.newTaskHook(task)
			}
			// Reject duplicate sealing work due to resubmitting.
			sealHash := w.engine.SealHash(task.block.Header())//获取区块在被签名之前的哈希值
			if sealHash == prev {
				continue
			}
			// Interrupt previous sealing operation
			interrupt()
			stopCh, prev = make(chan struct{}), sealHash

			if w.skipSealHook != nil && w.skipSealHook(task) {
				continue
			}
			w.pendingMu.Lock()//读写锁定
			w.pendingTasks[w.engine.SealHash(task.block.Header())] = task//构造map
			w.pendingMu.Unlock()
			//调用的共识引擎的块封装函数Seal来执行具体的挖矿操作。
			if err := w.engine.Seal(w.chain, task.block, w.resultCh, stopCh); err != nil {
				log.Warn("Block sealing failed", "err", err)
			}
```

上述代码是协程`worker.taskLoop()`中的`case task := <-w.taskCh`的代码，主要做了两件事：

+ 获取待签名区块哈希
+ 调用的共识引擎的块封装函数Seal来执行具体的挖矿操作

下面看`w.engine.Seal()`中到底做了什么。以太坊共识算法有`ethash`和`clique`两种，所以对应着有两种`Seal`方法的实现。`ethash`是`PoW`实现，`clique`是`PoA`实现，我们先看`ethash`的`Seal`方法。

```go
// Seal implements consensus.Engine, attempting to find a nonce that satisfies
// the block's difficulty requirements.
func (ethash *Ethash) Seal(chain consensus.ChainReader, block *types.Block, results chan<- *types.Block, stop <-chan struct{}) error {
	// If we're running a fake PoW, simply return a 0 nonce immediately
	// fake模式立即返回0作为nonce
	if ethash.config.PowMode == ModeFake || ethash.config.PowMode == ModeFullFake {
		header := block.Header()
		header.Nonce, header.MixDigest = types.BlockNonce{}, common.Hash{}
		select {
		case results <- block.WithSeal(header):
		default:
			ethash.config.Log.Warn("Sealing result is not read by miner", "mode", "fake", "sealhash", ethash.SealHash(block.Header()))
		}
		return nil
	}
	// If we're running a shared PoW, delegate sealing to it
	// 共享pow的话，则转到它的共享对象执行Seal操作
	if ethash.shared != nil {
		return ethash.shared.Seal(chain, block, results, stop)
	}
	// Create a runner and the multiple search threads it directs
	// 创建一个runner以及它指挥的多重搜索线程
	abort := make(chan struct{})

	ethash.lock.Lock()        // 线程上锁，保证内存的缓存（包含挖矿字段）安全
	threads := ethash.threads // 挖矿的线程s
	// ethash.rand为空，则为ethash的字段rand赋值
	if ethash.rand == nil {
		seed, err := crand.Int(crand.Reader, big.NewInt(math.MaxInt64)) // 获得种子
		if err != nil {
			// 执行失败，有报错，先解锁线程，程序中止，直接返回报错信息
			ethash.lock.Unlock()
			return err
		}
		ethash.rand = rand.New(rand.NewSource(seed.Int64())) // 执行成功，拿到合法种子seed，通过其获得rand对象，赋值。
	}
	ethash.lock.Unlock() // 解锁
	if threads == 0 {
		// 挖矿线程编号为0，则通过方法返回当前物理上可用CPU编号
		threads = runtime.NumCPU()
	}
	if threads < 0 {
		// 非法结果，线程置为0，允许在本地或远程没有额外逻辑的情况下，取消本地挖矿操作
		threads = 0 // Allows disabling local mining without extra logic around local/remote
	}
	// Push new work to remote sealer
	if ethash.remote != nil {
		ethash.remote.workCh <- &sealTask{block: block, results: results}
	}
	var (
		pend   sync.WaitGroup // 创建一个倒计时锁对象
		locals = make(chan *types.Block)
	)
	for i := 0; i < threads; i++ {
		pend.Add(1)
		go func(id int, nonce uint64) { // 核心代码通过闭包多线程技术来执行。
			defer pend.Done()
			ethash.mine(block, id, nonce, abort, locals) // Seal核心工作
		}(i, uint64(ethash.rand.Int63())) //闭包第二个参数表达式uint64(ethash.rand.Int63())通过上面准备好的rand函数随机数结果作为nonce实参传入方法体
	}
	// 直到seal操作被中止或者找到了一个nonce值，否则一直等
	// Wait until sealing is terminated or a nonce is found
	go func() {
		var result *types.Block // 定义一个区块对象result，用于接收操作结果并作为返回值返回上一层
		select {
		case <-stop:
			// Outside abort, stop all miner threads
			// 外部意外中止，停止所有挖矿线程
			close(abort)
		case result = <-locals:
			// One of the threads found a block, abort all others
			// 其中一个线程挖到正确块，中止其他所有线程
			select {
			case results <- result:
			default:
				ethash.config.Log.Warn("Sealing result is not read by miner", "mode", "local", "sealhash", ethash.SealHash(block.Header()))
			}
			close(abort)
		case <-ethash.update:
			// Thread count was changed on user request, restart
			// ethash对象发生改变，停止当前所有操作，重启当前方法
			close(abort)
			if err := ethash.Seal(chain, block, results, stop); err != nil {
				ethash.config.Log.Error("Failed to restart sealing after update", "err", err)
			}
		}
		// Wait for all miners to terminate and return the block
		// 等待所有矿工停止或者返回一个区块
		pend.Wait()
	}()
	return nil
}
```

函数的详细流程在代码注释中体现，此函数主要做了如下工作：

+ 使用随机数获取种子`seed`
+ 配置线程开始执行寻找`nonce`

寻找`nonce`的工作主要由上述代码第58行`ethash.mine(block, id, nonce, abort, locals)`执行，可以看出`Seal()`方法是对外的，而`mine()`方法是内部方法。

需要说明的是，`Seal()`函数调用`mine()`函数是通过启动协程的方式启动，所以在启动协程之后`Seal()`并不会等待`mine()`的结果，而是执行完成后直接返回。而`mine()`函数会在执行完毕后通过管道返回执行结果。

`ethash.mine()`函数如下

```go
// mine is the actual proof-of-work miner that searches for a nonce starting from
// seed that results in correct final block difficulty.
// mine函数是真正的pow矿工，用来搜索一个nonce值，nonce值开始于seed值，seed值是能最终产生正确的可匹配可验证的区块难度
func (ethash *Ethash) mine(block *types.Block, id int, seed uint64, abort chan struct{}, found chan *types.Block) {
	// Extract some data from the header
	// 从区块头中提取出一些数据，放在一个全局变量域中
	var (
		header  = block.Header()
		hash    = ethash.SealHash(header).Bytes()
		target  = new(big.Int).Div(two256, header.Difficulty)
		number  = header.Number.Uint64()
		dataset = ethash.dataset(number, false)
	)
	// Start generating random nonces until we abort or find a good one
	// 开始生成随机nonce值知道我们中止或者成功找到了一个合适的值
	var (
		attempts = int64(0) // 初始化一个尝试次数的变量，下面会利用该变量耍一些花枪
		nonce    = seed     // 初始化为seed值，后面每次尝试以后会累加
	)
	logger := ethash.config.Log.New("miner", id)
	logger.Trace("Started ethash search for new nonces", "seed", seed)
search:
	for {
		select {
		case <-abort:
			// Mining terminated, update stats and abort
			// 中止命令。挖矿中止，更新状态，中止当前操作，返回空
			logger.Trace("Ethash nonce search aborted", "attempts", nonce-seed)
			ethash.hashrate.Mark(attempts)
			break search

		default:
			// We don't have to update hash rate on every nonce, so update after after 2^X nonces
			// 我们没必要在每一次尝试nonce值的时候更新hash率，可以在尝试了2的X次方nonce值以后再更新即可
			attempts++
			if (attempts % (1 << 15)) == 0 {
				// 这里是定的2的15次方
				ethash.hashrate.Mark(attempts) // 满足条件了以后，要更新ethash的hash率字段的状态值
				attempts = 0                   // 重置尝试次数
			}
			// Compute the PoW value of this nonce
			// 为这个nonce值计算pow值
			digest, result := hashimotoFull(dataset.dataset, hash, nonce)
			if new(big.Int).SetBytes(result).Cmp(target) <= 0 {
				// Correct nonce found, create a new header with it
				// 找到正确nonce值，创建一个基于它的新的区块头
				header = types.CopyHeader(header)
				header.Nonce = types.EncodeNonce(nonce)// 将输入的整型值转换为一个区块nonce值
				header.MixDigest = common.BytesToHash(digest)// 将字节数组转换为Hash对象

				// Seal and return a block (if still needed)
				// 封装返回一个区块
				select {
				case found <- block.WithSeal(header):
					logger.Trace("Ethash nonce found and reported", "attempts", nonce-seed, "nonce", nonce)
				case <-abort:
					logger.Trace("Ethash nonce found but discarded", "attempts", nonce-seed, "nonce", nonce)
				}
				break search
			}
			// 累加nonce
			nonce++
		}
	}
	// Datasets are unmapped in a finalizer. Ensure that the dataset stays live
	// during sealing so it's not unmapped while being read.
	runtime.KeepAlive(dataset)
}
```

函数的详细流程在代码注释中体现，此函数主要做了如下工作：

+ 寻找`nonce`的操作
+ 找到`nonce`后重建区块头

至于如何判断`nonce`值是否正确，由第44行`if`条件语句来判断，以后再深层次挖掘。

区块封装后，协程`resultLoop()`开始执行。

```go
// resultLoop is a standalone goroutine to handle sealing result submitting
// and flush relative data to the database.
func (w *worker) resultLoop() {
	for {
		select {
		case block := <-w.resultCh:
			// Short circuit when receiving empty result.
			if block == nil {
				continue
			}
			// Short circuit when receiving duplicate result caused by resubmitting.
			if w.chain.HasBlock(block.Hash(), block.NumberU64()) {
				continue
			}
			var (
				sealhash = w.engine.SealHash(block.Header())
				hash     = block.Hash()
			)
			w.pendingMu.RLock()
			task, exist := w.pendingTasks[sealhash]
			w.pendingMu.RUnlock()
			if !exist {
				log.Error("Block found but no relative pending task", "number", block.Number(), "sealhash", sealhash, "hash", hash)
				continue
			}
			// Different block could share same sealhash, deep copy here to prevent write-write conflict.
			var (
				receipts = make([]*types.Receipt, len(task.receipts))
				logs     []*types.Log
			)
      // 处理交易生成收据
			for i, receipt := range task.receipts {
				// add block location fields
				receipt.BlockHash = hash
				receipt.BlockNumber = block.Number()
				receipt.TransactionIndex = uint(i)

				receipts[i] = new(types.Receipt)
				*receipts[i] = *receipt
				// Update the block hash in all logs since it is now available and not when the
				// receipt/log of individual transactions were created.
				for _, log := range receipt.Logs {
					log.BlockHash = hash
				}
				logs = append(logs, receipt.Logs...)
			}
			// Commit block and state to database.
			/* FuM:将区块写入到区块链中 */
			_, err := w.chain.WriteBlockWithState(block, receipts, logs, task.state, true)
			if err != nil {
				log.Error("Failed writing block to chain", "err", err)
				continue
			}
			log.Info("Successfully sealed new block", "number", block.Number(), "sealhash", sealhash, "hash", hash,
				"elapsed", common.PrettyDuration(time.Since(task.createdAt)))

			// Broadcast the block and announce chain insertion event
			/* FuM:向其他节点广播区块*/
			w.mux.Post(core.NewMinedBlockEvent{Block: block})

			// Insert the block into the set of pending ones to resultLoop for confirmations
			w.unconfirmed.Insert(block.NumberU64(), block.Hash())

		case <-w.exitCh:
			return
		}
	}
}
```

上述`resultLoop()`的`case block := <-w.resultCh`主要执行了以下工作：

+ 验证区块合法性
+ 为交易生成收据
+ 将区块写入到区块链中并提示`log`信息
+ 向其他节点广播区块
+ 将该区块写入待验证区块`unconfirmedBlock`中(第64行)

接下来会重复挖矿流程。

一个区块产生之后，它不是立即可信的，网络上的节点总是相信最长的链，当一条交易记录被打包进一个区块之后，就有了一个确认，而这个区块所在的链后面被再加入一个区块，就是第二个确认，如此下去，一个交易有了7个确认，我们就认为这个交易已经确定了，会被永远记录在区块链中。为什么是7个确认呢？因为每一个确认就是一个挖矿过程，都需要提供非常严格的计算，因此，这7个区块被同一个矿工创建的可能性微乎其微（可以说是不可能），因此矿工伪造交易也基本不可能。所以当挖出第8个待确认块，第一个待确认块会会被永远记录在区块链中。

相关`log`输出

```
🔨 mined potential block //挖出区块时
🔗 block reached canonical chain//区块确认后
⑂ block became an uncle //区块成为叔块
😱 block lost //区块丢失
Failed to retrieve header of mined block//区块头无法检索错误
```



## 算法

ethash包中包含几个algorithm开头的文件，这些文件的内容是pow核心算法，用来支持挖矿操作。

在共识引擎的`mine()`函数中，下面这句话是寻找nonce的重点

> ```go
> digest, result := hashimotoFull(dataset.dataset, hash, nonce)
> ```

###### hashimotoFull函数

```go
// 在传入的数据集中通过hash和nonce值计算加密值
func hashimotoFull(dataset []uint32, hash []byte, nonce uint64) ([]byte, []byte) {
    // 本函数核心代码段：定义一个lookup函数，用于在数据集中查找数据
	lookup := func(index uint32) []uint32 {
		offset := index * hashWords // hashWords是定义的常量值 =16
		return dataset[offset : offset+hashWords]
	}
	// hashimotoFull函数做的工作就是将原始数据集进行了读取分割，然后传给hashimoto函数。
	return hashimoto(hash, nonce, uint64(len(dataset))*4, lookup)
}
```

###### hashimoto函数

```go
// hashimoto aggregates data from the full dataset in order to produce our final
// value for a particular header hash and nonce.
func hashimoto(hash []byte, nonce uint64, size uint64, lookup func(index uint32) []uint32) ([]byte, []byte) {
	// Calculate the number of theoretical rows (we use one buffer nonetheless)
	rows := uint32(size / mixBytes)

	// Combine header+nonce into a 64 byte seed
	seed := make([]byte, 40)
	copy(seed, hash)
	binary.LittleEndian.PutUint64(seed[32:], nonce)

	seed = crypto.Keccak512(seed)
	seedHead := binary.LittleEndian.Uint32(seed)

	// Start the mix with replicated seed
	mix := make([]uint32, mixBytes/4)
	for i := 0; i < len(mix); i++ {
		mix[i] = binary.LittleEndian.Uint32(seed[i%16*4:])
	}
	// Mix in random dataset nodes
	temp := make([]uint32, len(mix))

	for i := 0; i < loopAccesses; i++ {
		parent := fnv(uint32(i)^seedHead, mix[i%len(mix)]) % rows
		for j := uint32(0); j < mixBytes/hashBytes; j++ {
			copy(temp[j*hashWords:], lookup(2*parent+j))
		}
		fnvHash(mix, temp)
	}
	// Compress mix
	for i := 0; i < len(mix); i += 4 {
		mix[i/4] = fnv(fnv(fnv(mix[i], mix[i+1]), mix[i+2]), mix[i+3])
	}
	mix = mix[:len(mix)/4]

	digest := make([]byte, common.HashLength)
	for i, val := range mix {
		binary.LittleEndian.PutUint32(digest[i*4:], val)
	}
	return digest, crypto.Keccak256(append(seed, digest...))
}
```

上述函数主要是通过数学计算得到`nonce`对应的加密值`digest`，`digest, result := hashimotoFull(dataset.dataset, hash, nonce)`拿到`digest`和`result`之后需要验证此加密值。

> ```new(big.Int).SetBytes(result).Cmp(target) <= 0	```

验证的方法很简单，只是使用`result`和`target`进行比较，如果小于等于0即为通过。`target`是在`mine`方法体中靠前的变量声明部分

> target = new(big.Int).Div(maxUint256, header.Difficulty)

可以看出，`target`的定义是根据区块头中的难度值运算而得出的。所以，我们可以通过调整`Difficulty`值，来控制`pow`运算难度，生成正确`nonce`的难度，达到`pow`工作量可控的目标。